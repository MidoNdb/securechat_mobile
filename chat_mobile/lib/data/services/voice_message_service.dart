// lib/data/services/voice_message_service.dart
// ‚úÖ Service complet pour messages vocaux E2EE

import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:get/get.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import '../models/message.dart';
import 'crypto_service.dart';
import 'file_service.dart';
import 'secure_storage_service.dart';
import '../api/dio_client.dart';
import '../api/api_endpoints.dart';

class VoiceMessageService extends GetxService {
  final CryptoService _crypto = Get.find<CryptoService>();
  final FileService _fileService = Get.find<FileService>();
  final SecureStorageService _storage = Get.find<SecureStorageService>();
  final DioClient _dio = Get.find<DioClient>();
  
  late final AudioRecorder _recorder;
  
  // √âtats observables
  final isRecording = false.obs;
  final recordingDuration = 0.obs;
  final currentAmplitude = 0.0.obs;
  
  String? _currentRecordingPath;
  DateTime? _recordingStartTime;
  
  // ==================== INITIALISATION ====================
  
  @override
  void onInit() {
    super.onInit();
    _recorder = AudioRecorder();
    print('‚úÖ VoiceMessageService initialis√©');
  }
  
  @override
  void onClose() {
    _recorder.dispose();
    super.onClose();
  }
  
  // ==================== ENREGISTREMENT ====================
  
  /// D√©marrer l'enregistrement audio
  Future<bool> startRecording() async {
    try {
      // 1. V√©rifier permissions
      if (!await _recorder.hasPermission()) {
        print('‚ùå Permission microphone refus√©e');
        return false;
      }
      
      // 2. Pr√©parer le fichier temporaire
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      _currentRecordingPath = '${tempDir.path}/voice_$timestamp.m4a';
      
      // 3. Configuration de l'enregistrement
      const config = RecordConfig(
        encoder: AudioEncoder.aacLc, // AAC pour compression
        bitRate: 128000,             // 128 kbps
        sampleRate: 44100,           // 44.1 kHz
        numChannels: 1,              // Mono
      );
      
      // 4. D√©marrer l'enregistrement
      await _recorder.start(
        config,
        path: _currentRecordingPath!,
      );
      
      isRecording.value = true;
      _recordingStartTime = DateTime.now();
      recordingDuration.value = 0;
      
      // 5. Timer pour mise √† jour dur√©e
      _startDurationTimer();
      
      // 6. Stream amplitude (pour animation)
      _startAmplitudeStream();
      
      print('üé§ Enregistrement d√©marr√©: $_currentRecordingPath');
      return true;
      
    } catch (e) {
      print('‚ùå Erreur startRecording: $e');
      isRecording.value = false;
      return false;
    }
  }
  
  /// Arr√™ter l'enregistrement et retourner le fichier
  Future<File?> stopRecording() async {
    try {
      if (!isRecording.value) {
        return null;
      }
      
      // 1. Arr√™ter l'enregistrement
      final path = await _recorder.stop();
      
      isRecording.value = false;
      _recordingStartTime = null;
      
      if (path == null) {
        print('‚ùå Enregistrement annul√©');
        return null;
      }
      
      // 2. V√©rifier le fichier
      final file = File(path);
      
      if (!await file.exists()) {
        print('‚ùå Fichier audio introuvable');
        return null;
      }
      
      final fileSize = await file.length();
      print('üé§ Enregistrement termin√©: ${fileSize ~/ 1024} KB, ${recordingDuration.value}s');
      
      return file;
      
    } catch (e) {
      print('‚ùå Erreur stopRecording: $e');
      isRecording.value = false;
      return null;
    }
  }
  
  /// Annuler l'enregistrement en cours
  Future<void> cancelRecording() async {
    try {
      if (isRecording.value) {
        await _recorder.stop();
        isRecording.value = false;
        _recordingStartTime = null;
        recordingDuration.value = 0;
        
        // Supprimer le fichier temporaire
        if (_currentRecordingPath != null) {
          final file = File(_currentRecordingPath!);
          if (await file.exists()) {
            await file.delete();
          }
        }
        
        print('üóëÔ∏è Enregistrement annul√©');
      }
    } catch (e) {
      print('‚ùå Erreur cancelRecording: $e');
    }
  }
  
  // ==================== ENVOI MESSAGE VOCAL ====================
  
  /// Envoyer un message vocal chiffr√© E2EE
  Future<Message> sendVoice({
    required String conversationId,
    required String recipientUserId,
    required File voiceFile,
  }) async {
    try {
      // 1. Lire les bytes du fichier audio
      final voiceBytes = await voiceFile.readAsBytes();
      
      // 2. Extraire m√©tadonn√©es
      final metadata = await _extractVoiceMetadata(voiceFile, voiceBytes);
      
      // 3. R√©cup√©rer cl√©s E2EE
      final myDhPrivateKey = await _storage.getDHPrivateKey();
      final mySignPrivateKey = await _storage.getSignPrivateKey();
      
      if (myDhPrivateKey == null || mySignPrivateKey == null) {
        throw Exception('Cl√©s E2EE manquantes');
      }
      
      // 4. R√©cup√©rer cl√©s publiques destinataire
      final recipientKeys = await _getRecipientPublicKeys(recipientUserId);
      
      // 5. Convertir en Base64
      final base64Voice = base64Encode(voiceBytes);
      
      // 6. Chiffrement E2EE
      final encrypted = await _crypto.encryptMessage(
        plaintext: base64Voice,
        myDhPrivateKeyB64: myDhPrivateKey,
        theirDhPublicKeyB64: recipientKeys['dh_public_key']!,
        mySignPrivateKeyB64: mySignPrivateKey,
      );
      
      // 7. Pr√©paration requ√™te
      final payload = {
        'conversation_id': conversationId,
        'recipient_user_id': recipientUserId,
        'type': 'VOICE',
        'encrypted_content': encrypted['ciphertext']!,
        'nonce': encrypted['nonce']!,
        'auth_tag': encrypted['auth_tag']!,
        'signature': encrypted['signature']!,
        'metadata': metadata,
      };
      
      // 8. Envoi HTTP
      final response = await _dio.privateDio.post(
        ApiEndpoints.sendMessage,
        data: payload,
      );
      
      // 9. Extraction message
      final messageData = response.data['data'] as Map<String, dynamic>;
      final message = Message.fromJson(messageData);
      
      // 10. Sauvegarder en cache
      await _fileService.saveToCacheDir(
        voiceBytes,
        message.id,
        extension: 'm4a',
      );
      
      print('‚úÖ Message vocal envoy√©: ${message.id}');
      
      // 11. Supprimer fichier temporaire
      if (await voiceFile.exists()) {
        await voiceFile.delete();
      }
      
      return message;
      
    } catch (e) {
      print('‚ùå Erreur sendVoice: $e');
      rethrow;
    }
  }
  
  // ==================== R√âCEPTION MESSAGE VOCAL ====================
  
  /// D√©chiffrer un message vocal re√ßu
  Future<File> decryptVoice(Message message) async {
    try {
      // 1. V√©rifier cache
      final cachedFile = await _fileService.getFromCache(message.id);
      if (cachedFile != null) {
        return cachedFile;
      }
      
      // 2. R√©cup√©rer cl√©s E2EE locales
      final myDhPrivateKey = await _storage.getDHPrivateKey();
      
      if (myDhPrivateKey == null) {
        throw Exception('Cl√© DH manquante');
      }
      
      // 3. ‚úÖ CORRECTION: Utiliser recipientUserId pour r√©cup√©rer les bonnes cl√©s
      // Si c'est MON message ‚Üí utiliser mes cl√©s publiques
      // Si c'est un message RE√áU ‚Üí utiliser les cl√©s de l'exp√©diteur
      final currentUserId = await _storage.getUserId();
      final isMyMessage = message.senderId == currentUserId;
      
      String keyUserId;
      if (isMyMessage && message.recipientUserId != null) {
        // Mon message ‚Üí d√©chiffrer avec les cl√©s du destinataire
        keyUserId = message.recipientUserId!;
      } else {
        // Message re√ßu ‚Üí d√©chiffrer avec les cl√©s de l'exp√©diteur
        keyUserId = message.senderId;
      }
      
      final otherKeys = await _getRecipientPublicKeys(keyUserId);
      
      // 4. D√©chiffrement E2EE
      final decryptedBase64 = await _crypto.decryptMessage(
        ciphertextB64: message.encryptedContent,
        nonceB64: message.nonce!,
        authTagB64: message.authTag!,
        signatureB64: message.signature!,
        myDhPrivateKeyB64: myDhPrivateKey,
        theirDhPublicKeyB64: otherKeys['dh_public_key']!,
        theirSignPublicKeyB64: otherKeys['sign_public_key']!,
      );
      
      // 5. D√©coder Base64
      final voiceBytes = base64Decode(decryptedBase64);
      
      // 6. Sauvegarder en cache
      final file = await _fileService.saveToCacheDir(
        Uint8List.fromList(voiceBytes),
        message.id,
        extension: 'm4a',
      );
      
      print('‚úÖ Message vocal d√©chiffr√©: ${message.id}');
      
      return file;
      
    } catch (e) {
      print('‚ùå Erreur decryptVoice: $e');
      rethrow;
    }
  }
  
  // ==================== M√âTADONN√âES ====================
  
  Future<Map<String, dynamic>> _extractVoiceMetadata(
    File voiceFile,
    Uint8List voiceBytes,
  ) async {
    try {
      final duration = recordingDuration.value;
      
      return {
        'duration': duration,
        'size': voiceBytes.length,
        'format': 'm4a',
        'codec': 'aac',
        'bitrate': 128000,
        'sample_rate': 44100,
        'channels': 1,
        'original_name': voiceFile.path.split('/').last,
      };
      
    } catch (e) {
      return {
        'size': voiceBytes.length,
        'format': 'm4a',
      };
    }
  }
  
  // ==================== R√âCUP√âRATION CL√âS ====================
  
  Future<Map<String, String>> _getRecipientPublicKeys(String userId) async {
    try {
      final response = await _dio.privateDio.get(
        ApiEndpoints.getPublicKeys(userId),
      );
      
      if (response.statusCode == 200) {
        final data = response.data['data'] as Map<String, dynamic>;
        
        return {
          'dh_public_key': data['dh_public_key'] as String,
          'sign_public_key': data['sign_public_key'] as String,
        };
      }
      
      throw Exception('Error ${response.statusCode}');
      
    } catch (e) {
      print('‚ùå Erreur r√©cup√©ration cl√©s: $e');
      rethrow;
    }
  }
  
  // ==================== HELPERS PRIV√âS ====================
  
  void _startDurationTimer() {
    Future.doWhile(() async {
      if (!isRecording.value) return false;
      
      await Future.delayed(const Duration(seconds: 1));
      
      if (isRecording.value && _recordingStartTime != null) {
        recordingDuration.value = 
          DateTime.now().difference(_recordingStartTime!).inSeconds;
      }
      
      return isRecording.value;
    });
  }
  
  void _startAmplitudeStream() {
    _recorder.onAmplitudeChanged(const Duration(milliseconds: 200))
      .listen((amplitude) {
        if (isRecording.value) {
          // Normaliser entre 0 et 1
          currentAmplitude.value = (amplitude.current + 50) / 50;
          currentAmplitude.value = currentAmplitude.value.clamp(0.0, 1.0);
        }
      });
  }
  
  // ==================== UTILITAIRES ====================
  
  /// V√©rifier si un message vocal est en cache
  Future<bool> isVoiceCached(String messageId) async {
    return await _fileService.existsInCache(messageId);
  }
  
  /// Supprimer un message vocal du cache
  Future<void> deleteVoiceFromCache(String messageId) async {
    await _fileService.deleteFromCache(messageId);
  }
  
  /// Formater la dur√©e en MM:SS
  String formatDuration(int seconds) {
    final minutes = seconds ~/ 60;
    final secs = seconds % 60;
    return '${minutes.toString().padLeft(2, '0')}:${secs.toString().padLeft(2, '0')}';
  }
  
  /// V√©rifier si on peut enregistrer
  Future<bool> hasRecordPermission() async {
    return await _recorder.hasPermission();
  }
}

